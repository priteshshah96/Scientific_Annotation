[
    {
        "paper_code": "JMIR_23_P_01",
        "abstract": "The ethics of generative artificial intelligence (AI) use in scientific manuscript content creation has become a serious matter of concern in the scientific publishing community. Generative AI has computationally become capable of elaborating research questions; refining programming code; generating text in scientific language; and generating images, graphics, or figures. However, this technology should be used with caution. In this editorial, we outline the current state of editorial policies on generative AI or chatbot use in authorship, peer review, and editorial processing of scientific and scholarly manuscripts. Additionally, we provide JMIR Publications’ editorial policies on these issues. We further detail JMIR Publications’ approach to the applications of AI in the editorial process for manuscripts in review in a JMIR Publications journal.",
        "events": [
          {
            "Background/Introduction": "",
            "Text": "The ethics of generative artificial intelligence (AI) use in scientific manuscript content creation has become a serious matter of concern in the scientific publishing community. Generative AI has computationally become capable of elaborating research questions; refining programming code; generating text in scientific language; and generating images, graphics, or figures. However, this technology should be used with caution.",
            "Main Action": "",
            "Arguments": {
              "Agent": "",
              "Object": {
                "Primary Object": "",
                "Primary Modifier": "",
                "Secondary Object": "",
                "Secondary Modifier": ""
              },
              "Context": "",
              "Purpose": "",
              "Method": "",
              "Results": "",
              "Analysis": "",
              "Challenge": "",
              "Ethical": "",
              "Implications": "",
              "Contradictions": ""
            }
          },
          {
            "Conclusions/Implications": "",
            "Text": "In this editorial, we outline the current state of editorial policies on generative AI or chatbot use in authorship, peer review, and editorial processing of scientific and scholarly manuscripts. Additionally, we provide JMIR Publications’ editorial policies on these issues. We further detail JMIR Publications’ approach to the applications of AI in the editorial process for manuscripts in review in a JMIR Publications journal.",
            "Main Action": "",
            "Arguments": {
              "Agent": "",
              "Object": {
                "Primary Object": "",
                "Primary Modifier": "",
                "Secondary Object": "",
                "Secondary Modifier": ""
              },
              "Context": "",
              "Purpose": "",
              "Method": "",
              "Results": "",
              "Analysis": "",
              "Challenge": "",
              "Ethical": "",
              "Implications": "",
              "Contradictions": ""
            }
          }
        ]
      },
      {
        "paper_code": "ACL_23_p_03",
        "abstract": "While the problem of hallucinations in neural machine translation has long been recognized, so far the progress on its alleviation is very little. Indeed, recently it turned out that without artificially encouraging models to hallucinate, previously existing methods fall short and even the standard sequence log-probability is more informative. It means that internal characteristics of the model can give much more information than we expect, and before using external models and measures, we first need to ask: how far can we go if we use nothing but the translation model itself? We propose to use a method that evaluates the percentage of the source contribution to a generated translation. Intuitively, hallucinations are translations detached from the source, hence they can be identified by low source contribution. This method improves detection accuracy for the most severe hallucinations by a factor of 2 and is able to alleviate hallucinations at test time on par with the previous best approach that relies on external models. Next, if we move away from internal model characteristics and allow external tools, we show that using sentence similarity from cross-lingual embeddings further improves these results. We release the code of our experiments.",
        "events": [
          {
            "Background/Introduction": "",
            "Text": "While the problem of hallucinations in neural machine translation has long been recognized, so far the progress on its alleviation is very little. Indeed, recently it turned out that without artificially encouraging models to hallucinate, previously existing methods fall short and even the standard sequence log-probability is more informative. It means that internal characteristics of the model can give much more information than we expect, and before using external models and measures, we first need to ask: how far can we go if we use nothing but the translation model itself?",
            "Main Action": "",
            "Arguments": {
              "Agent": "",
              "Object": {
                "Primary Object": "",
                "Primary Modifier": "",
                "Secondary Object": "",
                "Secondary Modifier": ""
              },
              "Context": "",
              "Purpose": "",
              "Method": "",
              "Results": "",
              "Analysis": "",
              "Challenge": "",
              "Ethical": "",
              "Implications": "",
              "Contradictions": ""
            }
          },
          {
            "Methods/Approach": "",
            "Text": "We propose to use a method that evaluates the percentage of the source contribution to a generated translation. Intuitively, hallucinations are translations detached from the source, hence they can be identified by low source contribution.",
            "Main Action": "",
            "Arguments": {
              "Agent": "",
              "Object": {
                "Primary Object": "",
                "Primary Modifier": "",
                "Secondary Object": "",
                "Secondary Modifier": ""
              },
              "Context": "",
              "Purpose": "",
              "Method": "",
              "Results": "",
              "Analysis": "",
              "Challenge": "",
              "Ethical": "",
              "Implications": "",
              "Contradictions": ""
            }
          },
          {
            "Results/Findings": "",
            "Text": "This method improves detection accuracy for the most severe hallucinations by a factor of 2 and is able to alleviate hallucinations at test time on par with the previous best approach that relies on external models. Next, if we move away from internal model characteristics and allow external tools, we show that using sentence similarity from cross-lingual embeddings further improves these results.",
            "Main Action": "",
            "Arguments": {
              "Agent": "",
              "Object": {
                "Primary Object": "",
                "Primary Modifier": "",
                "Secondary Object": "",
                "Secondary Modifier": ""
              },
              "Context": "",
              "Purpose": "",
              "Method": "",
              "Results": "",
              "Analysis": "",
              "Challenge": "",
              "Ethical": "",
              "Implications": "",
              "Contradictions": ""
            }
          },
          {
            "Conclusions/Implications": "",
            "Text": "We release the code of our experiments.",
            "Main Action": "",
            "Arguments": {
              "Agent": "",
              "Object": {
                "Primary Object": "",
                "Primary Modifier": "",
                "Secondary Object": "",
                "Secondary Modifier": ""
              },
              "Context": "",
              "Purpose": "",
              "Method": "",
              "Results": "",
              "Analysis": "",
              "Challenge": "",
              "Ethical": "",
              "Implications": "",
              "Contradictions": ""
            }
          }
        ]
      }
]