[
  {
    "paper_code": "JMIR_23_P_01",
    "abstract": "The ethics of generative artificial intelligence (AI) use in scientific manuscript content creation has become a serious matter of concern in the scientific publishing community. Generative AI has computationally become capable of elaborating research questions; refining programming code; generating text in scientific language; and generating images, graphics, or figures. However, this technology should be used with caution. In this editorial, we outline the current state of editorial policies on generative AI or chatbot use in authorship, peer review, and editorial processing of scientific and scholarly manuscripts. Additionally, we provide JMIR Publications’ editorial policies on these issues. We further detail JMIR Publications’ approach to the applications of AI in the editorial process for manuscripts in review in a JMIR Publications journal.",
    "events": [
      {
        "Background/Introduction": "ethics of gen ai",
        "Text": "The ethics of generative artificial intelligence (AI) use in scientific manuscript content creation has become a serious matter of concern in the scientific publishing community. Generative AI has computationally become capable of elaborating research questions; refining programming code; generating text in scientific language; and generating images, graphics, or figures. However, this technology should be used with caution.",
        "Main Action": "has become",
        "Arguments": {
          "Agent": "The ethics of generative artificial intelligence (AI)",
          "Object": {
            "Base Object": "a serious matter of concern",
            "Base Modifier": "in the scientific publishing community",
            "Attached Object": "",
            "Attached Modifier": ""
          },
          "Context": "use in scientific manuscript content creation",
          "Purpose": "",
          "Method": "",
          "Results": "",
          "Analysis": "",
          "Challenge": "this technology should be used with caution.",
          "Ethical": "",
          "Implications": "Generative AI has computationally become capable of elaborating research questions; refining programming code; generating text in scientific language; and generating images, graphics, or figures",
          "Contradictions": ""
        }
      },
      {
        "Conclusions/Implications": "Jmir publications",
        "Text": "In this editorial, we outline the current state of editorial policies on generative AI or chatbot use in authorship, peer review, and editorial processing of scientific and scholarly manuscripts. Additionally, we provide JMIR Publications’ editorial policies on these issues. We further detail JMIR Publications’ approach to the applications of AI in the editorial process for manuscripts in review in a JMIR Publications journal.",
        "Main Action": "outline",
        "Arguments": {
          "Agent": "we",
          "Object": {
            "Base Object": "the current state of editorial policies on generative AI or chatbot use",
            "Base Modifier": "in authorship, peer review, and editorial processing of scientific and scholarly manuscripts.",
            "Attached Object": "",
            "Attached Modifier": ""
          },
          "Context": [
            "In this editorial,",
            "we provide JMIR Publications’ editorial policies on these issues"
          ],
          "Purpose": "detail JMIR Publications’ approach to the applications of AI in the editorial process for manuscripts in review in a JMIR Publications journal.",
          "Method": "",
          "Results": "",
          "Analysis": "",
          "Challenge": "",
          "Ethical": "",
          "Implications": "",
          "Contradictions": ""
        }
      }
    ]
  },
  {
    "paper_code": "ACL_23_p_03",
    "abstract": "While the problem of hallucinations in neural machine translation has long been recognized, so far the progress on its alleviation is very little. Indeed, recently it turned out that without artificially encouraging models to hallucinate, previously existing methods fall short and even the standard sequence log-probability is more informative. It means that internal characteristics of the model can give much more information than we expect, and before using external models and measures, we first need to ask: how far can we go if we use nothing but the translation model itself? We propose to use a method that evaluates the percentage of the source contribution to a generated translation. Intuitively, hallucinations are translations detached from the source, hence they can be identified by low source contribution. This method improves detection accuracy for the most severe hallucinations by a factor of 2 and is able to alleviate hallucinations at test time on par with the previous best approach that relies on external models. Next, if we move away from internal model characteristics and allow external tools, we show that using sentence similarity from cross-lingual embeddings further improves these results. We release the code of our experiments.",
    "events": [
      {
        "Background/Introduction": "machine translation",
        "Text": "While the problem of hallucinations in neural machine translation has long been recognized, so far the progress on its alleviation is very little. Indeed, recently it turned out that without artificially encouraging models to hallucinate, previously existing methods fall short and even the standard sequence log-probability is more informative. It means that internal characteristics of the model can give much more information than we expect, and before using external models and measures, we first need to ask: how far can we go if we use nothing but the translation model itself?",
        "Main Action": "has long been recognized",
        "Arguments": {
          "Agent": "the problem of hallucinations in neural machine translation",
          "Object": {
            "Base Object": "the progress on its alleviation",
            "Base Modifier": "is very little.",
            "Attached Object": "",
            "Attached Modifier": ""
          },
          "Context": [
            "recently it turned out that without artificially encouraging models to hallucinate, previously existing methods fall short and even the standard sequence log-probability is more informative.",
            "before using external models and measures"
          ],
          "Purpose": "",
          "Method": "",
          "Results": "",
          "Analysis": "internal characteristics of the model can give much more information than we expect",
          "Challenge": "how far can we go if we use nothing but the translation model itself",
          "Ethical": "",
          "Implications": "",
          "Contradictions": ""
        }
      },
      {
        "Methods/Approach": "use a method that evaluates",
        "Text": "We propose to use a method that evaluates the percentage of the source contribution to a generated translation. Intuitively, hallucinations are translations detached from the source, hence they can be identified by low source contribution.",
        "Main Action": "propose",
        "Arguments": {
          "Agent": "We",
          "Object": {
            "Base Object": "use a method",
            "Base Modifier": "that evaluates the percentage of the source contribution to a generated translation",
            "Attached Object": "",
            "Attached Modifier": ""
          },
          "Context": "hallucinations are translations detached from the source,",
          "Purpose": "",
          "Method": "",
          "Results": "",
          "Analysis": "",
          "Challenge": "",
          "Ethical": "",
          "Implications": "hence they can be identified by low source contribution.",
          "Contradictions": ""
        }
      },
      {
        "Results/Findings": "sentence similarity from cross lingual embeddings",
        "Text": "This method improves detection accuracy for the most severe hallucinations by a factor of 2 and is able to alleviate hallucinations at test time on par with the previous best approach that relies on external models. Next, if we move away from internal model characteristics and allow external tools, we show that using sentence similarity from cross-lingual embeddings further improves these results.",
        "Main Action": "improves",
        "Arguments": {
          "Agent": "This method",
          "Object": {
            "Base Object": "detection accuracy for the most severe hallucinations",
            "Base Modifier": "by a factor of 2",
            "Attached Object": "able to alleviate hallucinations at test time",
            "Attached Modifier": "on par with the previous best approach that relies on external models."
          },
          "Context": "",
          "Purpose": "",
          "Method": "using sentence similarity from cross-lingual embeddings",
          "Results": "further improves these results",
          "Analysis": "",
          "Challenge": "",
          "Ethical": "",
          "Implications": "",
          "Contradictions": ""
        }
      },
      {
        "Conclusions/Implications": "code",
        "Text": "We release the code of our experiments.",
        "Main Action": "release",
        "Arguments": {
          "Agent": "We",
          "Object": {
            "Base Object": "the code",
            "Base Modifier": "of our experiments.",
            "Attached Object": "",
            "Attached Modifier": ""
          },
          "Context": "",
          "Purpose": "",
          "Method": "",
          "Results": "",
          "Analysis": "",
          "Challenge": "",
          "Ethical": "",
          "Implications": "",
          "Contradictions": ""
        }
      }
    ]
  }
]